![](https://cloud.overment.com/S04E02-1732553638.png)

Mamy za sobą już przynajmniej kilka przykładów operacji związanych z przetwarzaniem dokumentów, wczytywania różnych formatów danych i transformacji treści. Przeszliśmy także przez ich organizację w bazie danych oraz wyszukiwanie zarówno pełnotekstowe, jak i wyszukiwanie semantyczne. 

W dzisiejszej lekcji połączymy wszystko w całość, wprowadzając przy okazji kilka usprawnień w promptach i ich ewaluacji. Naszym głównym celem będzie stworzenie interfejsu, który za pomocą stosunkowo prostych funkcji umożliwi **wczytanie dokumentu**, jego **podsumowanie**, **odpowiedź na pytania na podstawie treści**, **tłumaczenie** oraz **wydobycie informacji**. Powodem, dla którego chcemy to zrobić, są agenci AI, których umiejętności będziemy chcieli możliwie jak najbardziej uprościć.

W rezultacie, możliwe będzie zlecenie następujących zadań: 

- Wejdź na stronę `https://...` i wypisz z niej wszystkie wspomniane narzędzia
- Pobierz ten dokument (`link do pliku DOCX`), a następnie przygotuj jego podsumowanie
- Przetłumacz `ten dokument` z polskiego na angielski
- Na podstawie plików `x, y, z` odpowiedz na pytania: `a, b, c`

Przykład implementacji pierwszego punktu w kodzie, widoczny jest na poniższym screenie. Wykorzystujemy w nim funkcję `process`, którą budowaliśmy w lekcji S03E04 — Źródła danych, dzięki czemu uzyskujemy dostęp do treści podanych stron www, w formie listy dokumentów. Następnie pobrana treść trafia do nowej funkcji `extract`, która pozwala nam na przekazanie opisu treści, którą LLM ma dla nas pobrać z treści. 

![](https://cloud.overment.com/2024-10-17/aidevs3_extract-be1d72f6-a.png)

Taki interfejs umożliwi nam w późniejszych lekcjach zbudowanie agenta, który będzie miał do dyspozycji listę umiejętności (funkcji). Będzie mógł je wywoływać w dowolnej kolejności z ustalonymi parametrami. Kompletna lista tych umiejętności znajduje się w przykładzie `docs` i klasie `DocumentService.ts`. 

![](https://cloud.overment.com/2024-10-17/aidevs3_actions-48bfcd39-1.png)

Lista dostępnych metod w tej chwili uwzględnia typowe akcje dla przetwarzania tekstu. Nic nie stoi jednak na przeszkodzie, aby rozbudować ją o kolejne umiejętności, takie jak: 

- Korekta dokumentu: poprawienie literówek z ewentualną korektą stylu i zwiększenia czytelności
- Weryfikacja dokumentu: sprawdzenie poprawności na podstawie bazowej wiedzy modelu oraz wyników wyszukiwania w Internecie
- Strukturyzowanie dokumentu: może to być akcja omawiana w przykładzie `notes`, odpowiedzialnym za strukturyzowanie notatek głosowych
- ...i inne.

Kluczowe w tej układance jest jednak to, że kolejne umiejętności budujemy poprzez **skorzystanie z istniejących już komponentów** i zestawów narzędzi. Nie musimy więc już tworzyć wszystkiego od podstaw, a w dodatku utrzymujemy kontrolę nad poszczególnymi komponentami. 
## Cele i zastosowania przetwarzania dokumentów

Przetwarzanie dokumentów kojarzy się z procesami biznesowymi, ale w naszym przypadku zagadnienie to jest znacznie szersze, ponieważ dotyczy większości działań, które będą podejmować agenci. Kilka przykładów: 

- Przeszukiwanie Internetu i praca z treścią stron www
- Klasyfikowanie wiadomości, zgłoszeń, plików
- Łączenie informacji z różnych źródeł
- Odsłuchiwanie wiadomości głosowych i filmów wideo
- Przetwarzanie historii konwersacji z użytkownikiem
- Organizowanie 'wspomnień' w pamięci długoterminowej

Można więc powiedzieć, że praktycznie wszystko na czym pracuje agent, będzie jakąś formą dokumentu. Natomiast **wszystkie akcje związane z ich przetwarzaniem** będą miały formę **narzędzia** o strukturze podobnej do przykładu `todo` omawianego w poprzedniej lekcji.

Zanim jednak je stworzymy, przyjrzyjmy się bliżej temu, jak zbudowane są poszczególne akcje. 
## Wczytywanie dokumentu do bazy danych i indeksowanie

Ze względu na rosnący limit okna kontekstu oraz prompt cache coraz częściej będziemy mieć komfort wczytania całej treści dokumentów do instrukcji systemowej. Nie zawsze jednak będzie to możliwe ze względu na precyzję zapytania, bądź pracę z modelami open source. Wówczas będziemy chcieli podzielić nasze treści na mniejsze fragmenty i dodać je do indeksów Qdrant oraz Algolia w celu późniejszego przeszukania z pomocą wyszukiwania hybrydowego omawianego w lekcji S03E03 — Wyszukiwanie Hybrydowe. 

Z punktu widzenia naszego interfejsu, wystarczy wczytanie dokumentów funkcją `process` (dzielącej treść na 1000 tokenów) oraz wykonanie funkcji `answer`. 

![](https://cloud.overment.com/2024-10-17/aidevs3_answer-fd9bbe4b-2.png)

Funkcja `process` w tym przypadku:

- **Rozpoznaje rodzaj źródła:** w tym przypadku jest to link kierujący do pliku, którego treść należy pobrać na dysk.
- **Dzieli tekst na mniejsze fragmenty:** konkretnie korzystając z tiktokenizera dzieli go na części nieprzekraczające 1000 tokenów oraz każdy z nich opisuje meta-danymi
- **Zwraca listę dokumentów**: rezultatem jej działania jest tablica obiektów opisujących poszczególne fragmenty

Następnie wykonujemy pętlę, która zapisuje dokumenty w bazie danych. Dodatkowo ustawiamy na `true` parametr odpowiedzialny za dodanie dokumentów do indeksów silników wyszukiwania. Przykład jednego z nich widoczny w Algolia znajduje się poniżej. 

![](https://cloud.overment.com/2024-10-17/aidevs3_index-80290d72-b.png)

Przygotowane dokumenty trafiają następnie do funkcji `answer` w której dochodzi do **wygenerowania zapytań zoptymalizowanych pod dwa rodzaje wyszukiwania**. Co ciekawe, jeśli zapytanie użytkownika jest złożone, to prompt `queriesPrompt` wygeneruje **serię podzapytań**.  

![](https://cloud.overment.com/2024-10-17/aidevs3_hybrid_queries-8543f038-9.png)

Wszystkie pary zapytań wykorzystywane są następnie do wykonania **równoległych** zapytań **z filtrem ograniczającym zakres wyszukiwania do dokumentów współdzielących `source_uuid`**. Ich rezultaty są agregowane na podstawie rankingu `RRF` i łączone w kontekst dla wypowiedzi modelu. 

![](https://cloud.overment.com/2024-10-17/aidevs3_hybrid_search-386e7d67-8.png)

Mamy więc do dyspozycji narzędzie z pomocą którego możemy "odpowiedzieć na pytania" praktycznie dowolnych treści przekazanych przez użytkownika. Musimy tylko mieć na uwadze fakt, że taki rodzaj wyszukiwania pozwoli nam jedynie na **odnajdywanie informacji znajdujących się w treści**, a nie uzyskiwania **ogólnej perspektywy** i analizowania zależności w dokumencie, bo do tego potrzebowalibyśmy bazy grafowej.

## Przetwarzanie fragmentów dokumentu

W lekcji S03E01 — Dokumenty mówiliśmy na temat limitu tokenów dla **treści generowanych przez model**, które wciąż są stosunkowo niskie. Dlatego dla transformacji wymagających **przepisania całego dokumentu** potrzebujemy przetworzenia każdego z fragmentów indywidualnie. 

Przykładem takiej akcji jest funkcja `translate`, która również wymaga przekazania listy dokumentów, których liczba tokenów **nie przekracza limitu tokenów wyjściowych** modelu z którym pracujemy. W moim przypadku uwzględniam tutaj jeszcze bufor, ponieważ dla każdego z dokumentów model generuje także serię "przemyśleń" na temat tego, jak przeprowadzić tłumaczenie. 

![](https://cloud.overment.com/2024-10-17/aidevs3_translation-af25933d-9.png)

W związku z tym, że tłumaczenie poszczególnych fragmentów może odbywać się niezależnie, proces umożliwia równoległe przetwarzanie pięciu z nich. Natomiast krytycznym elementem tego procesu jest upewnienie się, że **model zawsze zwróci nam tylko i wyłącznie przetłumaczoną treść**. W przeciwnym razie, gdy połączymy wszystkie fragmenty w całość otrzymamy dokument zawierający niepożądane komentarze. 

![](https://cloud.overment.com/2024-10-17/aidevs3_translate-715acac5-d.png)

Wiemy już, że o skuteczności promptu nie możemy być pewni. Możemy jednak zwiększać prawdopodobieństwo poprawnej odpowiedzi poprzez serię testów, które zweryfikują działanie promptu. Testy muszą w tym przypadku opierać się o ocenę ze strony modelu, którą w PromptFoo możemy przeprowadzić z pomocą typu `llm-rubric`. Przykłady kilku z nich można znaleźć w pliku `docs/prompts/translate.ts` oraz uruchomić poleceniem `bun docs/prompts/translate.ts`.

![](https://cloud.overment.com/2024-10-17/aidevs3_evaluations-0b7b3f02-2.png)

Poza odpowiedzią pozbawioną dodatkowych komentarzy, będzie interesowało nas także utrzymanie oryginalnego stylu wypowiedzi, co także adresujemy z pomocą promptu. 

## Efektywne przekazywanie długich treści w logice agenta

W lekcji S03E04 — Źródła danych omawialiśmy przykład `reference`, który pozwalał modelowi na posługiwanie się długimi treściami stosując do tego placeholder `[[uuid]]`, który programistycznie podmienialiśmy na docelową treść. Teraz na przykładzie `docs` widzimy jak duże znaczenie ma ta technika oraz dlaczego **zawsze będzie nam zależało na tym, aby treść dokumentu przechowywać w bazie danych (nawet tymczasowo)**.

W tym jednak przypadku nie będzie chodziło wyłącznie o sytuację w której treść przekazywana jest do użytkownika w odpowiedzi końcowej, ale także pomiędzy etapami jej przetwarzania (np. tłumaczenie → podsumowanie).

W przykładzie `docs` w tej chwili przekazywanie listy dokumentów odbywa się poprzez kod, ale nie zawsze tak będzie, ponieważ niekiedy to LLM będzie musiał zdecydować o tym, w jakie akcje uruchomić na wybranym zestawie danych. 

Nie bez powodu stosujemy tutaj `uuid`, którego przykładowa wartość wygląda tak: `601595c1-8646-4408-b2da-82522604a942`. Z punktu widzenia możliwości modelu jest to lepszy format niż `id` w formie liczbowej, ponieważ jeśli dojdzie tutaj do pomyłki w zapisie, to jesteśmy w stanie ją skutecznie wykryć. Niestety dalej pozostaje przestrzeń do pomylenia całego identyfikatora, ale tutaj ponownie do gry wchodzi zasada "weryfikacja jest prostsza, niż generowanie", czyli zastosowanie promptu weryfikującego podjętą decyzję. Ponownie nie mamy tutaj pewności o tym, że on także nie zawiedzie, lecz ryzyko takiej sytuacji znacznie spada. 

## Podsumowanie

Dzisiejsza lekcja pokazała nam to, do czego dążyliśmy od dłuższego czasu. Chodzi mianowicie o koncepcję zbudowania **zestawu narzędzi**, które będą zdolne do realizowania pojedynczych zadań, ale które będziemy w stanie **ze sobą łączyć w różnych konfiguracjach**. Co więcej, możliwość ta, będzie mogła być po części oddelegowana modelowi, co otwiera nam przestrzeń do budowania wyspecjalizowanych agentów AI. 

W przeciwieństwie do przykładu `todo` z poprzedniej lekcji, tutaj zamiast łączyć się z zewnętrznym API, opieramy się wyłącznie o możliwości modelu językowego oraz zestaw akcji zbudowany przez nas. Pomimo tego, nadal możemy zbudować na ich podstawie narzędzie dla modelu, dokładnie tak, jak zrobiliśmy to w przypadku Todoist.

Dlatego, jeśli masz zabrać tylko jedną rzecz z tej lekcji, spróbuj zastanowić się (lub najlepiej zbudować) nad logiką umożliwiającą komunikowanie się w naturalnym języku z akcjami, które dziś omówiliśmy.

Powodzenia!