![](https://cloud.overment.com/S03E04-1732097139.png)

Wiemy już całkiem sporo na temat organizacji treści, jej wyszukiwania oraz przekazywania do modelu. Nadszedł więc czas, abyśmy zatrzymali się nieco na źródłach danych i różnych formatach plików, których zawartość nie zawsze jest dostępna dla modelu. 

Choć multimodalność pozwala nam już na dość swobodne przetwarzanie obrazu, dźwięku czy nawet wideo, to wciąż mamy do czynienia z różnymi limitami, które wymagają działań po stronie kodu. Z kolei w przypadku innych formatów plików, takich jak pdf, xls, doc czy zip, sytuacja się komplikuje. 

Dziś narzędzia takie jak LangChain czy CrewAI dążą do tego, aby zaoferować nam łatwe wczytywanie różnych formatów plików. Szybko okazuje się jednak, że w domyślnie dostępnych 'loaderach' brakuje detali odpowiadających za tak krytyczne elementy, jak zarysowanie kontekstu dla modelu. Mam tutaj na myśli dokładnie metadane, o których rozmawialiśmy w lekcji S03E01 — Dokumenty i o które musimy samodzielnie zadbać.
## Praca z plikami i katalogami

Zawartość plików wczytywanych do kontekstu LLM powinna być zapisywana także na dysku (sam plik) oraz w bazie danych (informacje na temat pliku). Powodem jest tutaj nie tylko potrzeba skorzystania z tych danych w przyszłości, ale także sam proces przetwarzania, który może składać się z wielu kroków. 

![](https://cloud.overment.com/2024-10-11/aidevs3_filesystem-1c4b204a-f.png)

Dlatego w zależności od języka programowania z którym pracujesz, warto zapoznać się z dostępnym API pozwalającym na interakcję z systemem plików (file system). Poza tym, warto pamiętać o kilku detalach: 

- Wgrywane pliki powinny być podzielone na kategorie
- Struktura katalogów powinna uwzględniać datę utworzenia, abyśmy nie doprowadzili do sytuacji w której wewnątrz jednego folderu znajdują się dziesiątki tysięcy plików
- W strukturze katalogów warto uwzględnić `uuid` pliku, co pozwoli na uniknięcie przypadkowego nadpisania istniejącego dokumentu
- Warto zachowywać oryginalną nazwę pliku zarówno na dysku, jak i w danych zapisywanych w bazie
- Treść plików należy weryfikować na podstawie `mime-type`, a nie samej nazwy (o ile nie mówimy o pliku tekstowym, np. markdown)
- Pliki tymczasowe należy usuwać tak szybko, jak przestają być potrzebne

W bazie danych informacje na temat plików mogą pochodzić bezpośrednio z wygenerowanego dokumentu, którego przykład widzimy poniżej. 

![](https://cloud.overment.com/2024-10-11/aidevs3_docs-35c6c288-a.png)

Dokument ten opisuje treść pliku `xlsx`, który poza treścią tekstową (która posiada ograniczone formatowanie ze względu na konieczne uproszczenia), zawiera także właściwość `screenshots` z listą zrzutów ekranu poszczególnych arkuszy. W ten sposób model może 'dostrzec' złożone elementy, takie jak wykresy czy strukturę tabel. Poniżej przykład zrzutu ekranu arkusza, na którym widoczna jest prosta wizualizacja danych. 

![](https://cloud.overment.com/2024-10-11/aidevs3_chart-bb7ab82a-a.png)

Tymczasem do korzyści wynikających z przechowywania plików na dysku oraz bazie danych jeszcze wrócimy. 
## Wczytywanie treści plików

Odczytanie zawartości pliku plan/text, z perspektywy programistycznej, jest bardzo proste. Sprawa komplikuje się nieco bardziej w przypadku obrazów i plików audio, ale tutaj ze względu na możliwości LLM również można uznać to za stosunkowo proste. 

Problemy zaczynają się pojawiać przy dużych plikach, dużej liczbie plików lub gdy te kwestie się łączą. Również duże problemy występują przy formatach takich jak docx, xlsx czy PDF. Możliwości dotarcia do treści i jej transformacji różnią się w zależności od języka programowania. Jednak w zależności od sytuacji, możemy podejść do tego zadania w sposób nieco bardziej kreatywny i wykorzystać fakt, że ktoś włożył sporo wysiłku w to, aby obsłużyć różne typy dokumentów. 

W sieci możemy znaleźć wiele narzędzi i bibliotek oferujących możliwość zmiany formatu `xlsx -> csv` czy `docx -> HTML`. Większość z nich nie radzi sobie jednak nawet z dość prostymi strukturami, aczkolwiek warto i tak je sprawdzić, ponieważ mogą sprawdzić się w naszym przypadku. Znacznie lepiej wypadają tutaj usługi oferujące API, dla których ważnym elementem biznesu, jest poprawne odczytanie pliku. Jedną z takich firm jest Google. 

Przygotowałem więc przykład `loader` zdolny do wczytania treści plików o różnych formatach, za pośrednictwem prostej funkcji `process`, której zadaniem jest zwrócenie listy dokumentów (treść + metadata). 

![](https://cloud.overment.com/2024-10-11/aidevs3_loader-7c64e83d-2.png)

Ważne: do uruchomienia projektu i należy uzupełnić w pliku `.env` klucze `GOOGLE_PROJECT_ID`, `GOOGLE_PRIVATE_KEY_ID`, `GOOGLE_PRIVATE_KEY`, `GOOGLE_CLIENT_EMAIL`, `GOOGLE_CLIENT_ID`. Ich wartości można pobrać po utworzeniu projektu "[Google Cloud](https://console.cloud.google.com)" w którym należy uruchomić API Google Drive, Google Sheets i Google Docs. Następnie w zakładce [IAM & Admin](https://console.cloud.google.com/iam-admin/serviceaccounts?project=alice-384817) należy pobrać klucze dla IAM Account w formacie JSON (Manage Keys -> Add Keys -> JSON -> Create). 

![](https://cloud.overment.com/2024-10-11/aidevs3_keys-3b278f08-6.png)

Zacznijmy jednak od tego, że przykład ten oparłem o narzędzia z których sam korzystam, aczkolwiek w tym nowym wydaniu nie miałem jeszcze okazji sprawdzić ich skuteczności na większej skali. Dlatego z dużym prawdopodobieństwem kod ten zawiera jeszcze trochę błędów i może być zoptymalizowany na różne sposoby. 

Skupmy się jednak na jego funkcjonalności, która prezentuje się następująco: 

![](https://cloud.overment.com/2024-10-11/aidevs3_file_processing-b7567885-3.png)

Jak widać, obsługujemy cztery typy plików: pliki tekstowe (np. markdown), dokumenty (docx, xlsx), pliki PDF, obrazy oraz pliki audio. Konkretnie rozkłada się to następująco:

- **pliki tekstowe:** ze względu na prostą strukturę, są po prostu wczytywane i zamieniane na dokument, który ewentualnie może zostać podzielony na fragmenty
- **dokumenty:** docx/xlsx są w pierwszej kolejności wgrywane na Google Drive, a następnie pobierane w formie HTML lub CSV i dopiero wtedy na markdown. Dodatkowo pobieram je także w formacie PDF, którego poszczególne strony zamieniam na pliki JPG (zrzuty ekranu)
- **PDF**: ten format sprawia najwięcej problemu i nie spodziewam się, aby poradził sobie ze złożonymi strukturami. Zdarza mi się jednak odczytywać rachunki czy faktury, w związku z czym wykonuję jego zrzuty ekranu oraz (jeśli to możliwe) pobieram także jego treść
- **audio:** w pierwszej kolejności wykrywam ogólny poziom ciszy, a następnie segmentuję cały dokument na "fragmenty ciszy" i fragmenty podczas których ktoś mówi. Następnie dzielę cały plik na kawałki, uwzględniając mały bufor na początku oraz na końcu każdego z fragmentów. Pliki zamieniane są następnie na format `ogg` (bardzo optymalny), i poddawane transkrypcji przez OpenAI Whisper.
- **obrazy**: tutaj mam najmniejsze możliwości i wczytywanie dokumentów polega jedynie na ich przeprocesowaniu przez VLM, którego odpowiedź zamieniana jest na tekstową formę

Ostatecznie otrzymujemy odpowiedź w formie listy dokumentów gotowych do wczytania do kontekstu oraz bazy danych. 

Zatem, aby skorzystać z przykładu `loader`, wystarczy przekazanie ścieżki do pliku bądź adresu URL. Jeśli tylko jego format będzie zgodny z jednym z obsługiwanych, otrzymamy poprawną treść. Przez wspierane formaty rozumiem: 

- Pliki tekstowe: .txt, .md, .json, .html, .csv
- Pliki audio: .mp3, .mp4, .wav, .ogg
- Pliki obrazu: .jpg, .jpeg, .png, .gif, .bmp, .webp
- Dokumenty: .pdf, .doc, .docx, .xls, .xlsx
## Proxy dla zewnętrznego API

Dane dla LLM nie zawsze będą pochodzić z pliku. Nierzadko źródłem będzie zewnętrzna usługa (tak jak w przypadku przykładu `linear`), np. Notion czy dowolne inne API, dostarczające jakiś rodzaj informacji.

Choć teoretycznie moglibyśmy łączyć się bezpośrednio z zewnętrzną usługą, niemal zawsze będzie nam zależało na zbudowaniu własnego "proxy", które będzie pośredniczyło między naszym agentem a usługą.

Powodem jest większa elastyczność oraz możliwość dopasowania zarówno **formatu odpowiedzi, formatu błędów** czy **połączenia ze sobą informacji z różnych narzędzi**. 

Idea proxy nie jest szczególnie skomplikowana, ale zwracam na nią uwagę, ponieważ odgrywa istotną rolę w planowaniu struktury narzędzi dla agenta AI. W praktyce takie proxy mamy nawet w przykładzie `loader`, w którym odpowiedź ze strony Google Drive nie jest wczytywana natychmiast do kontekstu modelu, lecz wcześniej zamieniana na strukturę danych, spójną dla wszystkich pozostałych narzędzi, czyli dokumenty (mam na myśli "treść + metadata").
## Treści stron www

Przez pryzmat "dokumentów" można patrzeć także na treści stron www. Możemy zatem wykorzystać narzędzia takie jak FireCrawl (lub alternatywy) i połączyć je z logiką, którą mamy w przykładzie `loader`. 

Dzięki temu do metody `process` możemy przesłać dowolny adres URL pochodzący z dopuszczalnych przez nas domen. Wówczas treść strony zostanie zamieniona na format dokumentów i będzie gotowa do do pracy z LLM, a także zapisana w formie pliku `markdown`.

![](https://cloud.overment.com/2024-10-11/aidevs3_loadurl-43c708be-c.png)

W tym obszarze nie ma już nic nowego, poza tym, co omówiliśmy w przykładzie `websearch` i lekcji S01E01 — Interakcja.

## Zapamiętywanie informacji od użytkownika

Źródłem informacji może być także sama interakcja z LLM, w tym dane pochodzące od użytkownika oraz modelu. Rzecz w tym, że taka interakcja zwykle będzie wielopoziomowa, więc "przepisywanie" treści za każdym razem nie będzie wskazane. W zamian możemy wyposażyć model w możliwość zapisania treści pliku tak, aby w dalszych krokach posługiwał się wyłącznie identyfikatorem. 

Przykład `reference` pokazuje prosty scenariusz w którym model posiada informacje na temat dłuższego dokumentu wraz z instrukcją, że w razie potrzeby cytowania jego zawartości, powinien skorzystać z placeholder'a `[[uuid]]`. Następnie programistycznie podmieniamy treść, która może zostać przekazana do kolejnego promptu, bądź zwrócona użytkownikowi. 

![](https://cloud.overment.com/2024-10-11/aidevs3_reference-8022c484-0.png)

Praktyczną sytuacją w której możemy chcieli wykorzystać taki scenariusz, jest agent przesyłający mail. Poniżej widzimy treść jednej z takich wiadomości, w której Alice przesłała mi podsumowanie jednego z filmów na YouTube. 

![](https://cloud.overment.com/2024-10-11/aidevs3_email-4e75f072-7.png)

Zbierając to w całość: 

- Model powinien mieć możliwość odczytywania oraz zapisywania plików
- Poza zapisem pliku, model powinien mieć możliwość udostępnienia pliku i uzyskania do niego adresu URL na potrzeby dalszej pracy
- Model powinien mieć możliwość posługiwania się identyfikatorami / placeholderami dzięki którym nie będzie konieczne przepisywanie długich form treści (co nierzadko będzie też niemożliwe ze względu na limity output token).
- Praktycznie **każdy rodzaj danych** na których pracuje model, powinien (jest to sugestia, nie konieczność) być sprowadzony do jednego formatu, wspólnego dla wszystkich rodzajów treści. 

## Organizowanie danych w bazie

Zapisywanie danych dokumentów w bazie danych może przybierać różne formy, w zależności od tego, jak będziemy z nich korzystać. Najbardziej prawdopodobne scenariusze uwzględniają: 

- Połączenie dokumentu z użytkownikiem z zablokowaniem dostępu do jego treści innym użytkownikom
- Połączenie dokumentu z konwersacją, umożliwiające przywołanie kontekstu w razie wznowienia rozmowy
- Połączenie dokumentu z zadaniem realizowanym przez agenta i/lub etapem większego procesu, na wypadek konieczności wznowienia go
- Zapisywanie fragmentów przeprocesowanej treści. Np. tłumacząc długi dokument, zapisujemy ukończone fragmenty tak, aby móc wznowić proces w miejscu w którym pojawił się problem
- Zapisywanie oryginalnej treści dokumentu oraz jego zmienionych form na wypadek potrzeby odwołania się do niej lub powtórzenia procesu przetwarzania
- Zapisanie informacji o dacie wygaśnięcia dokumentu, szczególnie w przypadku plików udostępnionych pod publicznym adresem URL
- Powiązanie wpisu w bazie danych z zawartością pliku znajdującą się na dysku. W przypadku krótszych dokumentów (np. wygenerowanych chunków)) wskazane jest przechowywanie ich treści bezpośrednio w bazie. 

Sam temat przechowywania treści w bazie danych będzie pojawiać się jeszcze w kolejnych lekcjach AI_devs 3.
## Praca z wrażliwymi danymi

Wiemy już, że w przypadku pracy z plikami zawierającymi prywatne dane, możemy wykorzystać modele działające lokalnie bądź skorzystać z biznesowych planów usług takich jak Amazon Bedrock o ile pozwala na to regulamin firmy i umowy z klientami.

Jednak samo przetwarzanie danych przez model nie jest jedyną sytuacją o której powinniśmy pamiętać, ponieważ jeśli oddajemy w ręce modelu treść plików, to gdy związane z tym uprawnienia będą zbyt duże, narażamy się na wyciek danych. 

Przykładowo, jeśli to LLM będzie odpowiedzialny za zapisanie pliku i wskazanie użytkownika do którego ten plik ma być przypisany, to może dojść tutaj do pomyłki. W takiej sytuacji **konieczne jest kontrolowanie tego procesu po stronie programistycznej** i zapisanie pliku na podstawie aktywnej sesji czy tokenu użytkownika, który nie zależy od wyniku działania modelu. 

To samo dotyczy sytuacji w której model decyduje o wysłaniu wiadomości e-mail lub posługiwania się komunikatorem. Tutaj także konieczne jest narzucenie programistycznych ograniczeń. 

Zasadniczo zawsze gdy przy przetwarzaniu plików pojawia się przestrzeń na pomyłkę, musimy zaangażować tam kod lub w ostateczności człowieka. Np. wspomniane maile mogą być tworzone jako "szkice", które musi zaakceptować odpowiedzialna za to osoba. 

Kolejnym przykładem ograniczenia, z którego już korzystaliśmy, było limitowanie domen, które mogły być przeszukane lub scrapowane. Choć tam chodziło nam przede wszystkim o utrzymanie jakości treści, tak wątek zachowania prywatności również jest tutaj bardzo ważny. 

Złota zasada mówi więc o tym, aby **kontakt modelu z zewnętrznym światem był ograniczony tak bardzo, jak to możliwe** poprzez programistyczne ograniczenia. 
## Podsumowanie

Dzisiejsza lekcja pokazała nam, że LLM możemy połączyć z praktycznie dowolnym źródłem danych, aczkolwiek wymaga to sporego zaangażowania po stronie kodu.

Przekonaliśmy się także po raz kolejny, że narzucanie własnych ograniczeń na system jest krytyczne zarówno z punktu widzenia jego stabilności, jak i zachowania prywatności.

Ostatecznie jednak to od nas będzie zależało jak dużo swobody przekażemy w ręce modeli oraz czy będziemy weryfikować efekty ich pracy. Musimy mieć tylko na uwadze, że odpowiedzialność za działanie systemu ponosimy my, firma w której pracujemy bądź nasi klienci. Warto więc rozważnie podejść do tego tematu. 

Myślę także, że to, co zobaczyliśmy w tej lekcji w temacie wczytywania plików do kontekstu, dobrze łączy się ze wszystkim, czego nauczyliśmy się do tej pory. Dlatego tak ważne jest to, aby przetestować działanie przykładu `loader` i albo zapoznać się z jego treścią w celu jego dalszego rozwoju, albo stworzenia jego prostszej, bardziej dopasowanej do nas wersji. 

Zasadniczo narzędzie umożliwiające wczytywanie i zapis zewnętrznych źródeł danych do modelu, będzie nam niezbędne w kolejnych tygodniach szkolenia.