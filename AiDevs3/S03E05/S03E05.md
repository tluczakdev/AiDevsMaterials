![](https://cloud.overment.com/S03E05-1732262396.png)

Wyszukiwanie hybrydowe o którym mówiliśmy w lekcji S03E03 osiąga wysoką skuteczność w precyzyjnym docieraniu do informacji bezpośrednio zawartych w zestawie danych. Łatwo jednak spotkać codzienne sytuacje w których będzie nam zależało na uzyskaniu odpowiedzi na pytania wymagające czegoś więcej, niż "znalezienia igły w stogu siana". 

Wyobraźmy sobie sytuację, w której mamy agenta AI zdolnego do zapamiętywania informacji o zasobach wiedzy. Jego możliwości pozwolą nam łatwo przypomnieć sobie nazwę lub link do materiału, który widzieliśmy kilka miesięcy wcześniej, nawet jeśli nie podamy bezpośredniej nazwy, a jedynie ogólny opis. 

Dla porządku i łatwiejszego przeszukiwania, zasoby podzielone są na kategorie: **aplikacje, urządzenia, książki, kursy, filmy, materiały wideo, obrazki, społeczności, muzyka, artykuły, kanały youtube, dokumenty i notatki.**

![](https://cloud.overment.com/2024-10-13/aidevs3_resources-4031b42c-b.png)

Jeśli zapytamy o "bazę grafową", agent wybierze kategorię "apps" i bez problemu powiąże ją z notatką o Neo4J. Wyszukiwanie semantyczne w połączeniu z filtrem kategorii zawężającym obszar przeszukiwania będzie wystarczające.

![](https://cloud.overment.com/2024-10-13/aidevs3_simple_search-9be4642e-6.png)

Proces wyszukiwania znacznie skomplikuje się w przypadku zapytania o "**listę narzędzi, które zostały wymienione w materiałach na temat neo4j**". 

Tutaj nie wystarczy ani dopasowanie słów kluczowych, ani dopasowanie znaczenia. Nawet zastosowanie filtrów może okazać się niewystarczające, ponieważ sam proces wyszukiwania zaczyna się komplikować, nawet pomimo faktu, że mówimy o dość prostym zapytaniu.

W tym miejscu do gry wchodzą bazy grafowe, takie jak Neo4J dzięki którym wynik dla powyższego zapytania, prezentuje się następująco:

![](https://cloud.overment.com/2024-10-13/aidevs3_graph-987e68a7-e.png)

Jest to graf, którego struktura składa się z tzw. "node", które można porównać do dokumentów lub rekordów, oraz "edge" opisujących relacje pomiędzy nimi. Zarówno "node" jak i "edge" stanowią dwa podstawowe elementy struktury grafu. 

Dla naszego zapytania otrzymaliśmy więc centralny dokument na temat Neo4j. Został on powiązany z trzema dokumentami (2x artykuł, 1x video), które także posiadają swoje powiązania z dokumentami, które zostały wspomniane w ich treści. 

Uzyskanie takiego rezultatu było możliwe z pomocą jednego, prostego zapytania zapisanego w [Cypher](https://en.wikipedia.org/wiki/Cypher_(query_language)) (to query language, podobnie jak SQL). 

![](https://cloud.overment.com/2024-10-13/aidevs3_cypher-2450f2e0-8.png)

Wnioski są następujące: 

- Wyszukiwanie pełnotekstowe oraz znaczeniowe sprawdza się, gdy potrzebujemy precyzyjnie dotrzeć do informacji zawartych w zestawie danych. Natomiast uchwycenie szerokiej perspektywy lub odnalezienie powiązań, jest bardzo utrudnione
- Bazy grafowe pozwalają na budowanie powiązań pomiędzy dokumentami i nawigowanie po strukturze grafu w poszukiwaniu informacji rozproszonych po całym zestawie danych

Nasuwa to zasadne pytanie o to, w jakich sytuacjach baza grafowa może okazać się nam przydatna i czy rzeczywiście zawsze zaadresuje wszystkie nasze problemy. 
## Wprowadzenie do Neo4j

Podczas wybierania bazy grafowej, mamy do dyspozycji przynajmniej kilka opcji, jednak spośród wszystkich najbardziej wyróżnia się Neo4J. Jest to bardzo dojrzałe rozwiązanie, które sprawnie odnalazło się w świecie generatywnego AI. 

W naszym przypadku skorzystamy z wersji OpenSource, [której instalacja różni się od sytemu operacyjnego](https://neo4j.com/docs/operations-manual/current/installation/) (dla macOS wystarczy `brew install neo4j` oraz `neo4j start`). Domyślnie Neo4j będzie dostępne dla nas pod adresem `http://localhost:7474/` i gdy wszystko pójdzie w porządku, powinniśmy zobaczyć poniższy panel. 

![](https://cloud.overment.com/2024-10-13/aidevs3_neo4j_dashboard-f2b4f95d-5.png)

Poza tym będziemy korzystać także z `neo4j-javascript-driver`, aby połączyć się z neo4j po stronie kodu JavaScript / Node.js.

Sama składnia języka Cypher może być nowa dla wielu z nas, dlatego warto skorzystać z pomocy LLM do generowania podstawowych zapytań. Kilka z nich zapisałem w przykładzie `neo4j-101`. Po jego uruchomieniu do bazy zostanie dodanych kilka rekordów, a następnie zapytań wyświetlających dane w różnych konfiguracjach.

![](https://cloud.overment.com/2024-10-13/aidevs3_movies-36302f31-8.png)

Przykłady zapytań uwzględniają połączenia takie jak "Kto grał w filmie X", "Filmy w których grał aktor Y" czy "Którzy aktorzy grali wspólnie w więcej niż jednym filmie".

![](https://cloud.overment.com/2024-10-13/aidevs3_neo4j_queries-ec2bfd60-a.png)

Zrozumiałe powinny być już teraz możliwości grafowych baz danych oraz ich przewag. Natomiast wszystkie powyższe zapytania opierają się o bardzo konkretne dopasowania dokumentów, a na tym możliwości Neo4j się nie kończą.

Neo4j pozwala nam także na dodanie `vector index`, który pozwoli nam na przechowywanie embeddingu oraz przeszukiwanie dokumentów. To właśnie dzięki temu zapytanie o treści "Sauron" (imię głównego antagonisty Władcy Pierścieni) zostało poprawnie dopasowane do filmu oraz aktora "Hugo Waving'a" grającego Agenta Smitha w Matrixie oraz Elronda w serii LOTR. 

![](https://cloud.overment.com/2024-10-13/aidevs3_lotr-d126277b-1.png)

Podsumowując: 

- Zainstaluj Neo4J na swoim komputerze, dodaj zmienne środowiskowe w pliku `.env` i uruchom przykład `neo4j-101`
- Skorzystaj z pomocy LLM do generowania zapytań języka Cypher oraz zadaj kilka pytań na temat składni, aby móc ją zrozumieć przynajmniej w podstawowym zakresie
- Wskazówka: w celu usunięcia treści dokumentów z bazy Neo4j uruchom zapytanie: "MATCH (n) DETACH DELETE n" oraz "DROP INDEX `movie_index`" i "DROP INDEX `actor_index`". Możesz to zrobić w panelu Neo4j. 
## Strukturyzowanie danych

Przygotowanie danych na potrzeby grafowej bazy danych może polegać na strukturyzowaniu istniejących danych (np. pochodzących z Internetu), i/lub budowania grafu od podstaw w wyniku interakcji z agentem AI. Natomiast do samego budowania grafu możemy wykorzystać LLM, lub własne, wyspecjalizowane w danej domenie modele.

Już teraz dostępne są narzędzia takie jak [GraphRAG](https://microsoft.github.io/graphrag/) czy metody dostępne w LangChain, które oferują możliwość przekonwertowania nieustrukturyzowanego tekstu na serię dokumentów oraz połączeń pomiędzy nimi. Ustrukturyzowane dane mogą następnie zostać wykorzystane na potrzeby budowania kontekstu dla systemu RAG. 

![](https://cloud.overment.com/2024-10-13/aidevs3_graphrag-f291e1a9-5.png)

Na uwagę zasługują prompty wymienione [na stronie projektu](https://microsoft.github.io/graphrag/prompt_tuning/overview/), które skupiają się na: 

- Wypisaniu listy podmiotów i relacji między nimi
- Utworzeniu podsumowań opisujących podmioty i relacje
- Opisaniu stanu podmiotu i relacji w różnych kontekstach
- Opisaniu zależności pomiędzy podmiotami

Inaczej mówiąc, celem tych operacji jest wydobycie ustrukturyzowanych informacji w taki sposób, aby utworzone dokumenty były użyteczne na potrzeby kontekstu dla modelu. 

Nietrudno zauważyć, że przeprocesowanie dużej ilości treści będzie czasochłonne i kosztowne ze względu na konieczność wykonania wielu promptów dla tych samych zestawów danych. Obecnie kwestię kosztów możemy zaadresować poprzez cache promptów, natomiast nadal pozostaje problem skuteczności wydobywania i łączenia informacji.

Transformacja danych może odbywać się na podstawie z góry ustalonego schematu (np. lista bohaterów książki i relacji pomiędzy nimi), albo mieć charakter "open-ended" pozwalający na ukształtowanie schematu wraz z odkrywaniem kolejnych informacji. Ostatecznie strategia którą wybierzemy, będzie zależeć od potrzeb danego projektu i obie mają swoje wady oraz zalety.

W praktyce dość szybko okazuje się, że zbyt duża dowolność w tworzeniu dokumentów i relacji pomiędzy nimi, prowadzi do duplikacji treści oraz problemów z jej późniejszą aktualizacją. Dlatego podobnie jak w przypadku baz danych oraz indeksów silników wyszukiwania, należy zaplanować ścieżkę uwzględniającą **dostarczanie, organizację, odzyskiwanie i aktualizację** treści — czyli tematy, które poruszaliśmy na przestrzeni ostatnich lekcji. 

Ciekawy przykład, który może służyć jako pewien punkt odniesienia, kształtujący nasze wyobrażenie na temat strukturyzowania treści, pochodzi z repozytorium [funktio-ai-samples](https://github.com/JohannesJolkkonen/funktio-ai-samples). Konkretnie [w tym notebooku](https://github.com/JohannesJolkkonen/funktio-ai-samples/blob/main/knowledge-graph-demo/notebook.ipynb) można znaleźć przykładowe prompty odpowiedzialne za poszczególne etapy przetwarzania danych na potrzeby bazy grafowej. 

Poniżej znajduje się przykład promptu odpowiedzialnego za wypisanie listy podmiotów i ich powiązań. Choć ogólne założenie jest słuszne, nasze doświadczenia z poprzednich lekcji wskazują, że takie zadanie powinno być podzielone na co najmniej dwa etapy: pobieranie listy podmiotów oraz, przy użyciu drugiego promptu, opisywanie zależności dla każdego z nich. Dzięki temu model koncentruje się na jednej czynności, co zazwyczaj prowadzi do większej precyzji.

![](https://cloud.overment.com/2024-10-13/aidevs3_extrawcting-5253c3f3-f.png)

Podsumowując: 

- Praca z bazą grafową opiera się o dwa etapy: **strukturyzowania danych** i ich późniejszego **wyszukiwania**. 
- Dane na potrzeby bazy grafowej muszą zostać przekonwertowane na formę Node (Dokument) + Edge (Połączenie) z opisującymi je właściwościami.
- Transformacja zwykle będzie odbywać się z pomocą LLM i serii promptów odpowiedzialnych za pobieranie informacji oraz tworzenie powiązań.
- Ustrukturyzowane dane trafiają wówczas do bazy grafowej / indeksu wektorowego. Aktywność ta kończy etap strukturyzowania danych. 
- Proces wyszukiwania/wczytywania informacji na potrzeby kontekstu dla LLM odbywa się na podobnych zasadach jak w przypadku bazy wektorowej czy klasycznych silników wyszukiwania. Jednak w tym przypadku celem jest wygenerowanie zapytania Cypher (lub serii zapytań) i połączenie danych w jeden kontekst.

Przejdźmy więc do drugiego etapu, związanego z wyszukiwaniem informacji. 
## Grafy wiedzy i Retrieval Augmented Generation

Gdy mamy już ustrukturyzowane dane i bazę grafową gotową do przeszukiwania, to kolejnym krokiem jest jej połączenie z LLM. Podobnie jak w przypadku bazy wektorowej musimy wygenerować zapytania, a następnie zwrócone wyniki przeformatować tak, aby mogły zostać dołączone do kontekstu promptu systemowego. 

Chociaż LLM potrafią skutecznie generować zapytania SQL/Cypher, to poza sytuacjami budowania rozwiązań na własne potrzeby, wykorzystywanie tego do przeszukiwania całej bazy wiedzy nie jest dobrym pomysłem z powodu potencjalnego Prompt Injection. Zamiast tego, model powinien wskazywać obszary i zapytania, które programistycznie przekształcimy na docelowe zapytania, narzucając przy tym własne ograniczenia, takie jak poziom uprawnień dostępu do wybranych danych.

W przykładzie `neo4j` przygotowałem więc `Neo4jService` w którym znajduje się seria metod pełniących rolę interfejsu umożliwiającego komunikację pomiędzy modelem, a bazą grafową. Przykładowo poniżej mamy zapytanie, w przypadku którego LLM generuje zapytania oraz listę filtrów (która również jest parsowana w innym miejscu w kodzie tak, aby nie oddawać modelowi zbyt dużej odpowiedzialności). 

![](https://cloud.overment.com/2024-10-14/aidevs3_graph_interface-d1068a67-4.png)

Dodatkowo model ma do dyspozycji trzy rodzaje wyszukiwań (wynika to tylko z mojej decyzji):

- Przeszukiwanie ogólne: pobiera dokumenty z danej kategorii
- Przeszukiwanie wektorowe: pobiera dokumenty zbliżone znaczeniem do zapytania z opcjonalnym filtrowaniem względem kategorii
- Przeszukiwanie relacyjne: pobiera dokumenty zbliżone znaczeniem do zapytania, ale uwzględnia także możliwość pobrania informacji powiązanych z rezultatem (np. artykuły na temat wskazanego narzędzia)

Model w ramach jednego zapytania może zdecydować o wykonaniu kilku zapytań z każdej z kategorii. Jednak zamiast zwracać składnię Cypher, generuje tylko obiekt JSON z parametrami wyszukiwania. Poniżej mamy jeden z przykładów takiego obiektu, utworzonego na podstawie prośby o "Odnalezienie Neo4j i powiązanych z nim wideo".

![](https://cloud.overment.com/2024-10-14/aidevs3_graph_related_query-b1332ade-2.png)

Cała logika polega na zidentyfikowaniu, czy zapytanie użytkownika wymaga interakcji z pamięcią asystenta. Następnie, w zależności od podjętej decyzji, dane są zapamiętywane lub odczytywane, a informacje o tych działaniach zapisywane są w kontekście.

![](https://cloud.overment.com/2024-10-14/aidevs3_graph_rag-b2b32cd4-3.png)

Rozbijając to na kroki: 

1. **Analiza zapytania:** Jest to prompt decydujący o tym, jakie rodzaje akcji mają być podjęte (READ|WRITE|ANSWER) przez asystenta.
2. **Przypominanie:** Jest to seria promptów, w przypadku której dochodzi do opisania strategii wyszukiwania oraz zapytań w celu wczytania danych do kontekstu
3. **Zapamiętanie:** Jeśli model zdecyduje się na zapisanie informacji, to uruchamiany jest prompt opisujący nowy dokument oraz logika, która dodaje go do pamięci (w naszym przykładzie nie rozszerzałem go o tworzenie relacji pomiędzy dokumentami)
4. **Odpowiedź:** Na podstawie pobranego kontekstu generowana jest odpowiedź

Jest to prosty przykład implementacji GraphRAG, który obrazuje główne interakcje pomiędzy użytkownikiem, modelem, a źródłem danych. Jeśli jednak zdecydowalibyśmy się na korzystanie z niego, to koniecznie będzie rozbudowanie go o logikę łączenia ze sobą rekordów, a także weryfikacji tego, czy rekordy nie są **zduplikowane**.

Widzimy po nim także, że ogólny schemat systemu RAG jest zbliżony do tego, który omawialiśmy przy okazji wcześniejszych lekcji na temat wyszukiwania hybrydowego. Tutaj jednak zyskujemy nowe możliwości odpytywania bazy wiedzy, ale też musimy mierzyć się z nowymi problemami, takimi jak budowanie właściwych powiązań czy nawigowanie po strukturze grafu. 
## Podsumowanie

Bazy grafowe bez wątpienia są istotnym elementem generatywnych aplikacji i warto mieć je na uwadze przy podejmowaniu decyzji o doborze zestawu narzędzi. Dobrze je także uwzględnić na mapie swojego rozwoju i zdobywania nowych umiejętności, aczkolwiek w tym obszarze bardzo pomocne okazuje się także wsparcie ze strony LLM.

Sam nie posiadam jeszcze zbyt dużo praktycznego doświadczenia w pracy z grafowymi bazami danych i patrząc na materiały dostępne w sieci w obszarze łączenia grafów z LLM, wciąż jest jeszcze dość wcześnie. Dobrym źródłem wiedzy jest jednak oficjalny blog Neo4j, a także mniej oficjalne źródło w postaci kanału [NodusLabs](https://www.youtube.com/@noduslabs/videos). Co prawda jedno i drugie ukierunkowane jest na swoje własne produkty, tak wśród publikowanych materiałów można znaleźć wiele wartościowych wskazówek na temat budowania własnych narzędzi.

Poza tym wspomniałem także o GraphRAG oraz integracjach dostępnych w LangChain czy innych frameworkach. Nawet nasz przykład `neo4j` pokazuje, że zwykle zależy nam na dopasowaniu interakcji z grafem do własnych potrzeb, ale niekiedy gotowe rozwiązania mogą okazać się bardziej przydatne, chociażby ze względu na łatwość wdrożenia.

Jeśli masz zabrać z tej lekcji tylko jedną rzecz, to spróbuj połączyć przykład `neo4j-101` i zapisać, a następnie odczytać kilka zestawów własnych danych. Wykorzystaj także LLM w celu wyjaśnienia składni Cypher oraz generowania przykładowych zapytań.

Powodzenia!